<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Speech Synthesis - Article Demo</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>  
  <div class="controls">
    <div class="control-group">
      <label for="voiceSelect">Voice:</label>
      <select id="voiceSelect">
        <option value="">Loading voices...</option>
      </select>
    </div>
    <div class="control-group">
      <button id="playPauseBtn">▶️ Play</button>
      <button id="stopBtn">⏹️ Stop</button>
      <button id="prevBtn">⏮️ Previous</button>
      <button id="nextBtn">⏭️ Next</button>
      <span>Utterance: <span id="currentUtterance">1</span>/<span id="totalUtterances">-</span></span>
    </div>
  </div>

  <article id="content">
    <h1>Speech Synthesis</h1>
    
    <p>Speech synthesis is the artificial production of human speech. A computer system used for this purpose is called a speech synthesizer, and can be implemented in software or hardware products. A text-to-speech (TTS) system converts normal language text into speech; other systems render symbolic linguistic representations like phonetic transcriptions into speech.</p>
    
    <p>Synthesized speech can be created by concatenating pieces of recorded speech that are stored in a database. Systems differ in the size of the stored speech units; a system that stores phones or diphones provides the largest output range, but may lack clarity. For specific usage domains, the storage of entire words or sentences allows for high-quality output. Alternatively, a synthesizer can incorporate a model of the vocal tract and other human voice characteristics to create a completely "synthetic" voice output.</p>
    
    <p>The quality of a speech synthesizer is judged by its similarity to the human voice and by its ability to be understood clearly. An intelligible text-to-speech program allows people with visual impairments or reading disabilities to listen to written words on a home computer. The earliest computer operating system to have included a speech synthesizer was Unix in 1974, through the Unix speak utility. In 2000, Microsoft Sam was the default text-to-speech voice synthesizer used by the narrator accessibility feature, which shipped with all Windows 2000 operating systems, and subsequent Windows XP systems.</p>
    
    <p>A text-to-speech system (or "engine") is composed of two parts: a front-end and a back-end. The front-end has two major tasks. First, it converts raw text containing symbols like numbers and abbreviations into the equivalent of written-out words. This process is often called text normalization, pre-processing, or tokenization. The front-end then assigns phonetic transcriptions to each word, and divides and marks the text into prosodic units, like phrases, clauses, and sentences. The process of assigning phonetic transcriptions to words is called text-to-phoneme or grapheme-to-phoneme conversion. Phonetic transcriptions and prosody information together make up the symbolic linguistic representation that is output by the front-end. The back-end—often referred to as the synthesizer—then converts the symbolic linguistic representation into sound. In certain systems, this part includes the computation of the target prosody (pitch contour, phoneme durations), which is then imposed on the output speech.</p>
  </article>

  <footer class="attribution">
    <p>Text content is based on the Wikipedia article "<a href="https://en.wikipedia.org/wiki/Speech_synthesis" target="_blank" rel="noopener noreferrer">Speech synthesis</a>"</p>
    <p>Text is available under the <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener noreferrer">Creative Commons Attribution-ShareAlike License 4.0</a></p>
  </footer>

  <script type="module" src="script.js"></script>
</body>
</html>
